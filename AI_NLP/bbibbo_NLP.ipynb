{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5dd628-9f72-4eb6-96d1-ec9f2fdbae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       124\n",
      "           1       1.00      1.00      1.00        77\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      1.00      1.00       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Accuracy: 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data = pd.read_excel('varied_situation_texts.xlsx')\n",
    "okt = Okt()\n",
    "korean_stopwords = set(['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다'])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 특수 문자 및 불필요한 문자 제거\n",
    "    text = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣0-9\\s]', '', text)\n",
    "    \n",
    "    # 형태소 분석\n",
    "    tokens = okt.pos(text, norm=True, stem=True)  # 품사 태깅 (POS tagging)\n",
    "    \n",
    "    # 명사, 고유명사 및 중요한 단어만 남김\n",
    "    tokens = [word for word, tag in tokens if tag in ['Noun', 'ProperNoun', 'Adjective']]\n",
    "    \n",
    "    # 추가적인 불용어 제거\n",
    "    tokens = [word for word in tokens if word not in korean_stopwords]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data['processed_text'] = data['column_containing_text'].apply(preprocess_text)\n",
    "\n",
    "# 자동 라벨링\n",
    "disaster_keywords = ['홍수', '지진', '태풍', '화재', '재난', '사고', '비', '우박', '바람', \n",
    "                     '폭우', '코로나', '연기', '불', '화재', '화상', '방화', '경보', '신고', \n",
    "                     '소방차', '소방관', '폭발', '미세먼지', '폭염', '한파', '번개','낙뢰',\n",
    "                     '눈', '폭설', '눈사태', '추락', '붕괴', '재난', '응급', '긴급', '주의',\n",
    "                     '구조', '구급차', '사이렌', '교통사고', '위험', '비상', '위기', '테러',\n",
    "                     '폭탄', '인질', '전쟁', '대피', '감염', '바이러스', '격리', '정전', \n",
    "                     '해킹', '유출', '안전', '생명']\n",
    "\n",
    "def label_disaster(text):\n",
    "    for keyword in disaster_keywords:\n",
    "        if keyword in text:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "data['disaster_column'] = data['processed_text'].apply(label_disaster)\n",
    "\n",
    "# TF-IDF 피처 추출\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(data['processed_text'])\n",
    "y = data['disaster_column']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 나이브 베이즈 모델 학습 및 평가\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"=== Naive Bayes ===\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 전체 데이터에 대해 예측 및 결과 저장\n",
    "data['predicted_Naive_Bayes'] = model.predict(X)\n",
    "\n",
    "# 예측 결과 엑셀 파일 저장\n",
    "data.to_excel('final_disaster_predictions.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
